{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTBP_QYuu6tc"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==3.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiU_ES5tzpMH"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spkccRiv0CB3"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "# classifier = pipeline(\"zero-shot-classification\", device=0) # to utilize GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWiovVJG9ei_"
      },
      "source": [
        "We can use this pipeline by passing in a sequence and a list of candidate labels. The pipeline assumes by default that only one of the candidate labels is true, returning a list of scores for each label which add up to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "hkfE6NRA0Dzy",
        "outputId": "8b3f9e37-3e46-4b25-813b-c5fa7bbc3c97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['politics', 'economics', 'public health'],\n",
              " 'scores': [0.972518801689148, 0.01458414364606142, 0.012897025793790817],\n",
              " 'sequence': 'Who are you voting for in 2020?'}"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"politics\", \"public health\", \"economics\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGXwxxyn9nOC"
      },
      "source": [
        "To do multi-class classification, simply pass `multi_class=True`. In this case, the scores will be independent, but each will fall between 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ZvZeVb2h5RX0",
        "outputId": "9ba085bf-4c52-4011-9c51-3a0adeddd3a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['politics', 'elections', 'public health', 'economics'],\n",
              " 'scores': [0.972069501876831,\n",
              "  0.967610776424408,\n",
              "  0.03248710557818413,\n",
              "  0.0061644683592021465],\n",
              " 'sequence': 'Who are you voting for in 2020?'}"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"Who are you voting for in 2022 ?\"\n",
        "candidate_labels = [\"politics\", \"public health\", \"economics\", \"elections\"]\n",
        "\n",
        "classifier(sequence, candidate_labels, multi_class=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLLeDT1r9-yQ"
      },
      "source": [
        "Here's an example of sentiment classification:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "f7AF53Wl5f8W",
        "outputId": "50a52076-7d2b-4ce0-b95f-c9cf9a13b361"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['negative', 'positive'],\n",
              " 'scores': [0.9916268587112427, 0.00837317667901516],\n",
              " 'sequence': 'I hated this movie. The acting sucked.'}"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"I hated this movie.\"\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "5yLx3pRr5xQA",
        "outputId": "6420fb46-9aeb-4055-8ab6-fdc5eb822a60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'labels': ['negative', 'positive'],\n",
              "  'scores': [0.9916267991065979, 0.008373182266950607],\n",
              "  'sequence': 'I hated this movie. The acting sucked.'},\n",
              " {'labels': ['negative', 'positive'],\n",
              "  'scores': [0.8148515820503235, 0.1851484179496765],\n",
              "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = [\n",
        "    \"I hated this movie. The acting sucked.\",\n",
        "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
        "]\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "\n",
        "classifier(sequences, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrpyGWM782R"
      },
      "source": [
        "The second example is a bit harder. Let's see if we can improve the results by using a hypothesis template which is more specific to the setting of review sentiment analysis. Instead of the default, `This example is {}.`, we'll use, `The sentiment of this review is {}.` (where `{}` is replaced with the candidate class name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "kqx5hp7X8XNA",
        "outputId": "69c6e083-f3dc-41db-fca5-d96a3541f1fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'labels': ['negative', 'positive'],\n",
              "  'scores': [0.9890093207359314, 0.010990672744810581],\n",
              "  'sequence': 'I hated this movie. The acting sucked.'},\n",
              " {'labels': ['positive', 'negative'],\n",
              "  'scores': [0.9581228494644165, 0.0418771356344223],\n",
              "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = [\n",
        "    \"I hated this movie. The acting sucked.\",\n",
        "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
        "]\n",
        "candidate_labels = [\"positive\", \"negative\"]\n",
        "hypothesis_template = \"The sentiment of this review is {}.\"\n",
        "\n",
        "classifier(sequences, candidate_labels, hypothesis_template=hypothesis_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iArbRAe781-_"
      },
      "source": [
        "By providing a more precise hypothesis template, we are able to see a more accurate classification of the second review.\n",
        "\n",
        "> Note that sentiment classification is used here just as an illustrative example. The [Hugging Face Model Hub](https://huggingface.co/models?filter=text-classification) has a number of models trained specifically on sentiment tasks which can be used instead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxUTOnllSH4w"
      },
      "source": [
        "#### Update: Zero-shot classification in 100 languages\n",
        "\n",
        "Interested in using the pipeline for languages other than English? We've trained a cross-lingual model on top of XLM RoBERTa which you can use by passing `model='joeddav/xlm-roberta-large-xnli'` when creating the pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siZhFPekSN7t"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model='joeddav/xlm-roberta-large-xnli')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrcljZ75UxKN"
      },
      "source": [
        "You can use it with any combination of languages. For example, let's classify a Russian sentence with English candidate labels:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "gBJyFwC2TwGv",
        "outputId": "5e683b8a-2e9f-46c2-95f9-04559bed04ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['politics', 'Europe', 'public health'],\n",
              " 'scores': [0.9048484563827515, 0.05722189322113991, 0.03792969882488251],\n",
              " 'sequence': 'За кого вы голосуете в 2020 году?'}"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9hGVMsrVI8S"
      },
      "source": [
        "Now let's do the same but with the labels in French:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0xKYBOLYVeNJ",
        "outputId": "a8066bb5-9e95-4f80-d77b-9753cc4c4be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['politique', 'Europe', 'santé publique'],\n",
              " 'scores': [0.9726154804229736, 0.017128489911556244, 0.010256024077534676],\n",
              " 'sequence': 'За кого вы голосуете в 2020 году?'}"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
        "candidate_labels = [\"Europe\", \"santé publique\", \"politique\"]\n",
        "\n",
        "classifier(sequence, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHURJUPCVgGP"
      },
      "source": [
        "As we discussed in the last section, the default hypothesis template is the English, `This text is {}.`. If you are working strictly within one language, it may be worthwhile to translate this to the language you are working with:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ZCtTclt7VpMv",
        "outputId": "87c768b3-2193-4164-d993-0ee9c9eec3ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['política', 'Europa', 'salud pública'],\n",
              " 'scores': [0.9109585881233215, 0.05954807624220848, 0.029493311420083046],\n",
              " 'sequence': '¿A quién vas a votar en 2020?'}"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence = \"¿A quién vas a votar en 2020?\"\n",
        "candidate_labels = [\"Europa\", \"salud pública\", \"política\"]\n",
        "hypothesis_template = \"Este ejemplo es {}.\"\n",
        "\n",
        "classifier(sequence, candidate_labels, hypothesis_template=hypothesis_template)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
